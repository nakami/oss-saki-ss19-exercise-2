{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sF_9MAOKPyAY"
   },
   "source": [
    "Resume NER Part 4: Working with Flair NLP\n",
    "\n",
    "---\n",
    "\n",
    "In this part we will use flair NLP to train a model on our data and evaluate the results. Please make sure you have set up your Google account and uploaded your files to Google drive. This Notebook should run on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXoVFeGlQdEu"
   },
   "source": [
    "Let's change the working directory to the Google drive where our training data is, and install flair nlp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2zuCubbF-AQc",
    "outputId": "9f3cd1e5-f27b-453d-94b0-23575606aacb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXiOU9ihIHvX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/SAKI_2019/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "l8542ZPSnM_d",
    "outputId": "55520d55-bc93-43af-c4de-0c65ab922b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.1.0)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
      "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
      "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.7)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n",
      "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
      "Requirement already satisfied: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.6.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.3)\n",
      "Requirement already satisfied: pytorch-pretrained-bert>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.6.2)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->flair) (1.16.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.2)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (41.0.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.0.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (0.1.82)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.167)\n",
      "Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.13.2)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.167 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.167)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.167->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n"
     ]
    }
   ],
   "source": [
    "# download flair library #\n",
    "! pip install flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOWwKlH8QwBU"
   },
   "source": [
    "In the next section, we will train a NER model with flair. This code is taken from the flair nlp tutorials section 7. \"Training a model\" \n",
    "https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "yNxo9VgEEj0q",
    "outputId": "9a5d99c7-1e0c-4274-da92-0cbbaf8905dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " converted_resumes.json\t\t       resources        training_bilou.txt\n",
      "'Entity Recognition in Resumes.json'   test_bilou.txt\n"
     ]
    }
   ],
   "source": [
    "#! mv '/content/gdrive/My Drive/SAKI_2019/data/training_bilou (2).txt' '/content/gdrive/My Drive/SAKI_2019/data/training_bilou.txt'\n",
    "! ls '/content/gdrive/My Drive/SAKI_2019/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Ghp5-JZTRYOb",
    "outputId": "89a6690b-846d-4ee0-d641-7ec2d97114d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-18 14:52:31,636 Reading data from /content/gdrive/My Drive/SAKI_2019/data\n",
      "2019-06-18 14:52:31,640 Train: /content/gdrive/My Drive/SAKI_2019/data/training_bilou.txt\n",
      "2019-06-18 14:52:31,645 Dev: None\n",
      "2019-06-18 14:52:31,647 Test: /content/gdrive/My Drive/SAKI_2019/data/test_bilou.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated function (or staticmethod) load_column_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:312: DeprecationWarning: Call to deprecated function (or staticmethod) read_column_data. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, column_format\n",
      "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:318: DeprecationWarning: Call to deprecated function (or staticmethod) read_column_data. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, column_format\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: 9401 train + 1044 dev + 3100 test sentences\n",
      "[b'<unk>', b'O', b'B-Name', b'L-Name', b'-', b'B-Designation', b'L-Designation', b'B-Degree', b'I-Degree', b'L-Degree', b'I-Designation', b'U-Degree', b'U-Designation', b'I-Name', b'<START>', b'<STOP>']\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "from flair.datasets import Corpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "\n",
    "## make sure this describes your file structure\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# folder where training and test data are\n",
    "data_folder = '/content/gdrive/My Drive/SAKI_2019/data'\n",
    "\n",
    "# 1.0 is full data, try a much smaller number like 0.1 to test run the code\n",
    "downsample = 1.0\n",
    "\n",
    "## your train file name\n",
    "train_file = 'training_bilou.txt'\n",
    "\n",
    "## your test file name\n",
    "test_file = 'test_bilou.txt'\n",
    "# 1. get the corpus\n",
    "corpus: Corpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
    "                                                             train_file=train_file,\n",
    "                                                             test_file=test_file,\n",
    "                                                           dev_file=None).downsample(downsample)\n",
    "print(corpus)\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')\n",
    "print(tag_dictionary.idx2item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "o6H1IzUbR5iH",
    "outputId": "1a785455-bf02-4c7d-d468-6f7315731f5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# 4. initialize embeddings. Experiment with different embedding types to see what gets the best results\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, CharacterEmbeddings, FlairEmbeddings\n",
    "from typing import List\n",
    "\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    WordEmbeddings('glove'),\n",
    "    # comment in this line to use character embeddings\n",
    "    CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings (needs a LONG time to train :-)\n",
    "    #FlairEmbeddings('news-forward'),\n",
    "    #FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type='ner',\n",
    "                                        use_crf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3961
    },
    "colab_type": "code",
    "id": "xFMA2qsyTvHq",
    "outputId": "1926a603-0b74-4207-a5a4-005e1a3f4f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-18 14:53:00,163 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 14:53:00,165 Evaluation method: MICRO_F1_SCORE\n",
      "2019-06-18 14:53:00,636 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 14:53:02,337 epoch 1 - iter 0/294 - loss 88.17574310\n",
      "2019-06-18 14:53:23,454 epoch 1 - iter 29/294 - loss 11.84778854\n",
      "2019-06-18 14:53:44,233 epoch 1 - iter 58/294 - loss 8.29505000\n",
      "2019-06-18 14:54:08,515 epoch 1 - iter 87/294 - loss 6.89873970\n",
      "2019-06-18 14:54:32,620 epoch 1 - iter 116/294 - loss 6.12702840\n",
      "2019-06-18 14:55:02,538 epoch 1 - iter 145/294 - loss 5.47876507\n",
      "2019-06-18 14:55:23,447 epoch 1 - iter 174/294 - loss 4.97724392\n",
      "2019-06-18 14:55:45,851 epoch 1 - iter 203/294 - loss 4.69156968\n",
      "2019-06-18 14:56:07,959 epoch 1 - iter 232/294 - loss 4.47649900\n",
      "2019-06-18 14:56:30,913 epoch 1 - iter 261/294 - loss 4.25605112\n",
      "2019-06-18 14:56:53,052 epoch 1 - iter 290/294 - loss 4.03805016\n",
      "2019-06-18 14:56:58,967 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 14:56:58,975 EPOCH 1 done: loss 4.0277 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 14:57:16,387 DEV : loss 1.709194302558899 - score 0.2131\n",
      "2019-06-18 14:58:00,931 TEST : loss 2.0527758598327637 - score 0.2309\n",
      "2019-06-18 14:58:04,895 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 14:58:06,251 epoch 2 - iter 0/294 - loss 2.28403449\n",
      "2019-06-18 14:58:31,067 epoch 2 - iter 29/294 - loss 2.38021900\n",
      "2019-06-18 14:58:56,580 epoch 2 - iter 58/294 - loss 2.19944485\n",
      "2019-06-18 14:59:17,155 epoch 2 - iter 87/294 - loss 2.13438825\n",
      "2019-06-18 14:59:40,588 epoch 2 - iter 116/294 - loss 2.04427447\n",
      "2019-06-18 15:00:03,391 epoch 2 - iter 145/294 - loss 2.00146707\n",
      "2019-06-18 15:00:23,675 epoch 2 - iter 174/294 - loss 1.93766857\n",
      "2019-06-18 15:00:46,605 epoch 2 - iter 203/294 - loss 1.88799278\n",
      "2019-06-18 15:01:12,514 epoch 2 - iter 232/294 - loss 1.90256270\n",
      "2019-06-18 15:01:35,203 epoch 2 - iter 261/294 - loss 1.88244418\n",
      "2019-06-18 15:01:57,541 epoch 2 - iter 290/294 - loss 1.85435172\n",
      "2019-06-18 15:02:00,234 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:02:00,236 EPOCH 2 done: loss 1.8502 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 15:02:17,780 DEV : loss 1.1303091049194336 - score 0.5135\n",
      "2019-06-18 15:03:01,887 TEST : loss 1.3693568706512451 - score 0.4584\n",
      "2019-06-18 15:03:05,674 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:03:07,057 epoch 3 - iter 0/294 - loss 0.92913979\n",
      "2019-06-18 15:03:29,908 epoch 3 - iter 29/294 - loss 1.57588906\n",
      "2019-06-18 15:03:52,595 epoch 3 - iter 58/294 - loss 1.51827999\n",
      "2019-06-18 15:04:17,244 epoch 3 - iter 87/294 - loss 1.49965714\n",
      "2019-06-18 15:04:40,379 epoch 3 - iter 116/294 - loss 1.48480145\n",
      "2019-06-18 15:05:03,190 epoch 3 - iter 145/294 - loss 1.45427309\n",
      "2019-06-18 15:05:23,342 epoch 3 - iter 174/294 - loss 1.45022965\n",
      "2019-06-18 15:05:49,114 epoch 3 - iter 203/294 - loss 1.50258984\n",
      "2019-06-18 15:06:12,660 epoch 3 - iter 232/294 - loss 1.51041887\n",
      "2019-06-18 15:06:36,070 epoch 3 - iter 261/294 - loss 1.47220478\n",
      "2019-06-18 15:06:57,319 epoch 3 - iter 290/294 - loss 1.45897017\n",
      "2019-06-18 15:06:59,740 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:06:59,741 EPOCH 3 done: loss 1.4505 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 15:07:17,155 DEV : loss 0.9230380654335022 - score 0.5823\n",
      "2019-06-18 15:08:01,255 TEST : loss 1.15884530544281 - score 0.5155\n",
      "2019-06-18 15:08:05,011 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:08:06,668 epoch 4 - iter 0/294 - loss 1.02255630\n",
      "2019-06-18 15:08:30,574 epoch 4 - iter 29/294 - loss 1.28132576\n",
      "2019-06-18 15:08:51,995 epoch 4 - iter 58/294 - loss 1.34748356\n",
      "2019-06-18 15:09:13,184 epoch 4 - iter 87/294 - loss 1.28183734\n",
      "2019-06-18 15:09:35,104 epoch 4 - iter 116/294 - loss 1.34061970\n",
      "2019-06-18 15:10:01,866 epoch 4 - iter 145/294 - loss 1.36137053\n",
      "2019-06-18 15:10:23,356 epoch 4 - iter 174/294 - loss 1.31549871\n",
      "2019-06-18 15:10:44,779 epoch 4 - iter 203/294 - loss 1.29707367\n",
      "2019-06-18 15:11:08,801 epoch 4 - iter 232/294 - loss 1.27036994\n",
      "2019-06-18 15:11:31,110 epoch 4 - iter 261/294 - loss 1.26131075\n",
      "2019-06-18 15:11:55,516 epoch 4 - iter 290/294 - loss 1.26550907\n",
      "2019-06-18 15:11:58,137 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:11:58,139 EPOCH 4 done: loss 1.2606 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 15:12:15,347 DEV : loss 0.8157801628112793 - score 0.6165\n",
      "2019-06-18 15:12:58,345 TEST : loss 1.041659951210022 - score 0.5433\n",
      "2019-06-18 15:13:01,998 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:13:03,326 epoch 5 - iter 0/294 - loss 0.42682132\n",
      "2019-06-18 15:13:28,290 epoch 5 - iter 29/294 - loss 1.02739873\n",
      "2019-06-18 15:13:49,569 epoch 5 - iter 58/294 - loss 1.08824819\n",
      "2019-06-18 15:14:12,545 epoch 5 - iter 87/294 - loss 1.09292892\n",
      "2019-06-18 15:14:37,792 epoch 5 - iter 116/294 - loss 1.13319622\n",
      "2019-06-18 15:15:02,388 epoch 5 - iter 145/294 - loss 1.10793290\n",
      "2019-06-18 15:15:26,229 epoch 5 - iter 174/294 - loss 1.14155932\n",
      "2019-06-18 15:15:48,683 epoch 5 - iter 203/294 - loss 1.13893410\n",
      "2019-06-18 15:16:12,674 epoch 5 - iter 232/294 - loss 1.15247820\n",
      "2019-06-18 15:16:33,234 epoch 5 - iter 261/294 - loss 1.16146809\n",
      "2019-06-18 15:16:57,751 epoch 5 - iter 290/294 - loss 1.16850866\n",
      "2019-06-18 15:17:02,735 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:17:02,738 EPOCH 5 done: loss 1.1628 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 15:17:17,617 DEV : loss 0.7627096772193909 - score 0.6286\n",
      "2019-06-18 15:18:01,609 TEST : loss 1.0067118406295776 - score 0.5769\n",
      "2019-06-18 15:18:05,365 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:18:06,964 epoch 6 - iter 0/294 - loss 0.62382829\n",
      "2019-06-18 15:18:34,809 epoch 6 - iter 29/294 - loss 1.17621603\n",
      "2019-06-18 15:18:56,075 epoch 6 - iter 58/294 - loss 1.17052152\n",
      "2019-06-18 15:19:17,787 epoch 6 - iter 87/294 - loss 1.10576025\n",
      "2019-06-18 15:19:40,369 epoch 6 - iter 116/294 - loss 1.06346767\n",
      "2019-06-18 15:20:05,470 epoch 6 - iter 145/294 - loss 1.04778632\n",
      "2019-06-18 15:20:26,582 epoch 6 - iter 174/294 - loss 1.04566792\n",
      "2019-06-18 15:20:50,670 epoch 6 - iter 203/294 - loss 1.04662486\n",
      "2019-06-18 15:21:12,372 epoch 6 - iter 232/294 - loss 1.05256543\n",
      "2019-06-18 15:21:32,300 epoch 6 - iter 261/294 - loss 1.06603436\n",
      "2019-06-18 15:21:58,481 epoch 6 - iter 290/294 - loss 1.07626646\n",
      "2019-06-18 15:22:01,191 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:22:01,192 EPOCH 6 done: loss 1.0721 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 15:22:16,331 DEV : loss 0.7458456754684448 - score 0.6152\n",
      "2019-06-18 15:23:01,715 TEST : loss 0.9712508320808411 - score 0.5595\n",
      "2019-06-18 15:23:01,723 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:23:03,035 epoch 7 - iter 0/294 - loss 1.28700066\n",
      "2019-06-18 15:23:25,563 epoch 7 - iter 29/294 - loss 0.94165627\n",
      "2019-06-18 15:23:48,786 epoch 7 - iter 58/294 - loss 1.08526206\n",
      "2019-06-18 15:24:11,848 epoch 7 - iter 87/294 - loss 1.01941578\n",
      "2019-06-18 15:24:31,924 epoch 7 - iter 116/294 - loss 0.99926426\n",
      "2019-06-18 15:24:53,066 epoch 7 - iter 145/294 - loss 0.98319721\n",
      "2019-06-18 15:25:17,243 epoch 7 - iter 174/294 - loss 0.99003565\n",
      "2019-06-18 15:25:40,217 epoch 7 - iter 203/294 - loss 0.99006122\n",
      "2019-06-18 15:26:04,255 epoch 7 - iter 232/294 - loss 0.98057214\n",
      "2019-06-18 15:26:28,786 epoch 7 - iter 261/294 - loss 1.00009859\n",
      "2019-06-18 15:26:50,894 epoch 7 - iter 290/294 - loss 1.00436467\n",
      "2019-06-18 15:26:53,435 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:26:53,436 EPOCH 7 done: loss 0.9986 - lr 0.1000 - bad epochs 1\n",
      "2019-06-18 15:27:08,165 DEV : loss 0.7023515701293945 - score 0.6264\n",
      "2019-06-18 15:27:53,898 TEST : loss 0.9147149324417114 - score 0.5797\n",
      "2019-06-18 15:27:53,905 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:27:55,235 epoch 8 - iter 0/294 - loss 0.58513808\n",
      "2019-06-18 15:28:19,017 epoch 8 - iter 29/294 - loss 1.00389418\n",
      "2019-06-18 15:28:40,075 epoch 8 - iter 58/294 - loss 0.92978400\n",
      "2019-06-18 15:29:02,795 epoch 8 - iter 87/294 - loss 0.93698097\n",
      "2019-06-18 15:29:22,910 epoch 8 - iter 116/294 - loss 0.92903640\n",
      "2019-06-18 15:29:48,775 epoch 8 - iter 145/294 - loss 0.92298193\n",
      "2019-06-18 15:30:12,281 epoch 8 - iter 174/294 - loss 0.93275287\n",
      "2019-06-18 15:30:33,246 epoch 8 - iter 203/294 - loss 0.93126512\n",
      "2019-06-18 15:30:56,469 epoch 8 - iter 232/294 - loss 0.97254455\n",
      "2019-06-18 15:31:22,129 epoch 8 - iter 261/294 - loss 0.98272523\n",
      "2019-06-18 15:31:44,563 epoch 8 - iter 290/294 - loss 0.97559666\n",
      "2019-06-18 15:31:47,222 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:31:47,227 EPOCH 8 done: loss 0.9753 - lr 0.1000 - bad epochs 2\n",
      "2019-06-18 15:32:01,823 DEV : loss 0.6663967370986938 - score 0.6422\n",
      "2019-06-18 15:32:46,991 TEST : loss 0.8315432667732239 - score 0.5953\n",
      "2019-06-18 15:32:50,689 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:32:52,198 epoch 9 - iter 0/294 - loss 0.85437095\n",
      "2019-06-18 15:33:12,355 epoch 9 - iter 29/294 - loss 0.90094235\n",
      "2019-06-18 15:33:38,898 epoch 9 - iter 58/294 - loss 0.92989819\n",
      "2019-06-18 15:34:01,312 epoch 9 - iter 87/294 - loss 0.99162864\n",
      "2019-06-18 15:34:20,988 epoch 9 - iter 116/294 - loss 0.99232016\n",
      "2019-06-18 15:34:49,142 epoch 9 - iter 145/294 - loss 0.99338843\n",
      "2019-06-18 15:35:09,843 epoch 9 - iter 174/294 - loss 0.96942002\n",
      "2019-06-18 15:35:34,432 epoch 9 - iter 203/294 - loss 0.96405233\n",
      "2019-06-18 15:35:58,655 epoch 9 - iter 232/294 - loss 0.96546387\n",
      "2019-06-18 15:36:19,816 epoch 9 - iter 261/294 - loss 0.95749307\n",
      "2019-06-18 15:36:40,523 epoch 9 - iter 290/294 - loss 0.95062465\n",
      "2019-06-18 15:36:43,022 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:36:43,024 EPOCH 9 done: loss 0.9520 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 15:37:00,424 DEV : loss 0.6626825332641602 - score 0.6139\n",
      "2019-06-18 15:37:44,261 TEST : loss 0.8355284929275513 - score 0.5783\n",
      "2019-06-18 15:37:44,268 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:37:45,527 epoch 10 - iter 0/294 - loss 0.72568220\n",
      "2019-06-18 15:38:07,705 epoch 10 - iter 29/294 - loss 1.00329903\n",
      "2019-06-18 15:38:30,950 epoch 10 - iter 58/294 - loss 0.95540557\n",
      "2019-06-18 15:38:54,076 epoch 10 - iter 87/294 - loss 0.93614177\n",
      "2019-06-18 15:39:15,219 epoch 10 - iter 116/294 - loss 0.91946742\n",
      "2019-06-18 15:39:39,285 epoch 10 - iter 145/294 - loss 0.91552982\n",
      "2019-06-18 15:40:00,785 epoch 10 - iter 174/294 - loss 0.90405739\n",
      "2019-06-18 15:40:20,756 epoch 10 - iter 203/294 - loss 0.89589958\n",
      "2019-06-18 15:40:45,720 epoch 10 - iter 232/294 - loss 0.90719513\n",
      "2019-06-18 15:41:08,826 epoch 10 - iter 261/294 - loss 0.91408929\n",
      "2019-06-18 15:41:32,071 epoch 10 - iter 290/294 - loss 0.91681316\n",
      "2019-06-18 15:41:34,460 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:41:34,462 EPOCH 10 done: loss 0.9182 - lr 0.1000 - bad epochs 1\n",
      "2019-06-18 15:41:51,437 DEV : loss 0.6247597336769104 - score 0.6442\n",
      "2019-06-18 15:42:34,476 TEST : loss 0.7875044345855713 - score 0.6088\n",
      "2019-06-18 15:42:38,193 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:42:40,078 epoch 11 - iter 0/294 - loss 1.28206897\n",
      "2019-06-18 15:43:06,502 epoch 11 - iter 29/294 - loss 0.89113744\n",
      "2019-06-18 15:43:31,796 epoch 11 - iter 58/294 - loss 0.95029158\n",
      "2019-06-18 15:43:54,785 epoch 11 - iter 87/294 - loss 0.97100888\n",
      "2019-06-18 15:44:16,681 epoch 11 - iter 116/294 - loss 0.93873886\n",
      "2019-06-18 15:44:37,115 epoch 11 - iter 145/294 - loss 0.93095616\n",
      "2019-06-18 15:44:59,953 epoch 11 - iter 174/294 - loss 0.93474360\n",
      "2019-06-18 15:45:21,754 epoch 11 - iter 203/294 - loss 0.90909675\n",
      "2019-06-18 15:45:42,360 epoch 11 - iter 232/294 - loss 0.90212242\n",
      "2019-06-18 15:46:03,880 epoch 11 - iter 261/294 - loss 0.89530940\n",
      "2019-06-18 15:46:29,676 epoch 11 - iter 290/294 - loss 0.88252406\n",
      "2019-06-18 15:46:32,099 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:46:32,100 EPOCH 11 done: loss 0.8810 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 15:46:46,779 DEV : loss 0.6165211796760559 - score 0.6503\n",
      "2019-06-18 15:47:29,719 TEST : loss 0.7849340438842773 - score 0.6036\n",
      "2019-06-18 15:47:33,469 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:47:35,005 epoch 12 - iter 0/294 - loss 1.82669759\n",
      "2019-06-18 15:47:59,533 epoch 12 - iter 29/294 - loss 0.92974095\n",
      "2019-06-18 15:48:22,446 epoch 12 - iter 58/294 - loss 0.85430403\n",
      "2019-06-18 15:48:45,001 epoch 12 - iter 87/294 - loss 0.88616293\n",
      "2019-06-18 15:49:09,636 epoch 12 - iter 116/294 - loss 0.89174844\n",
      "2019-06-18 15:49:34,905 epoch 12 - iter 145/294 - loss 0.88098064\n",
      "2019-06-18 15:49:56,230 epoch 12 - iter 174/294 - loss 0.87698561\n",
      "2019-06-18 15:50:17,504 epoch 12 - iter 203/294 - loss 0.87890969\n",
      "2019-06-18 15:50:38,320 epoch 12 - iter 232/294 - loss 0.88252807\n",
      "2019-06-18 15:51:00,507 epoch 12 - iter 261/294 - loss 0.87166069\n",
      "2019-06-18 15:51:20,954 epoch 12 - iter 290/294 - loss 0.86031344\n",
      "2019-06-18 15:51:23,431 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:51:23,432 EPOCH 12 done: loss 0.8604 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 15:51:38,260 DEV : loss 0.6105525493621826 - score 0.6253\n",
      "2019-06-18 15:52:22,659 TEST : loss 0.7756816148757935 - score 0.6082\n",
      "2019-06-18 15:52:22,666 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:52:24,293 epoch 13 - iter 0/294 - loss 1.55918407\n",
      "2019-06-18 15:52:45,967 epoch 13 - iter 29/294 - loss 0.82732248\n",
      "2019-06-18 15:53:07,979 epoch 13 - iter 58/294 - loss 0.78678319\n",
      "2019-06-18 15:53:35,941 epoch 13 - iter 87/294 - loss 0.82130326\n",
      "2019-06-18 15:53:59,738 epoch 13 - iter 116/294 - loss 0.82772486\n",
      "2019-06-18 15:54:22,897 epoch 13 - iter 145/294 - loss 0.85888113\n",
      "2019-06-18 15:54:45,373 epoch 13 - iter 174/294 - loss 0.86559742\n",
      "2019-06-18 15:55:05,699 epoch 13 - iter 203/294 - loss 0.85685873\n",
      "2019-06-18 15:55:25,480 epoch 13 - iter 232/294 - loss 0.84302741\n",
      "2019-06-18 15:55:50,829 epoch 13 - iter 261/294 - loss 0.86308293\n",
      "2019-06-18 15:56:11,465 epoch 13 - iter 290/294 - loss 0.85286229\n",
      "2019-06-18 15:56:13,910 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:56:13,911 EPOCH 13 done: loss 0.8518 - lr 0.1000 - bad epochs 1\n",
      "2019-06-18 15:56:28,622 DEV : loss 0.6085161566734314 - score 0.6697\n",
      "2019-06-18 15:57:13,941 TEST : loss 0.7875271439552307 - score 0.5886\n",
      "2019-06-18 15:57:17,659 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 15:57:19,624 epoch 14 - iter 0/294 - loss 0.85418195\n",
      "2019-06-18 15:57:46,037 epoch 14 - iter 29/294 - loss 0.96640641\n",
      "2019-06-18 15:58:10,386 epoch 14 - iter 58/294 - loss 0.90850801\n",
      "2019-06-18 15:58:32,893 epoch 14 - iter 87/294 - loss 0.87349088\n",
      "2019-06-18 15:58:55,568 epoch 14 - iter 116/294 - loss 0.87976948\n",
      "2019-06-18 15:59:15,560 epoch 14 - iter 145/294 - loss 0.86273724\n",
      "2019-06-18 15:59:38,756 epoch 14 - iter 174/294 - loss 0.84627592\n",
      "2019-06-18 16:00:00,526 epoch 14 - iter 203/294 - loss 0.82944728\n",
      "2019-06-18 16:00:22,139 epoch 14 - iter 232/294 - loss 0.82761509\n",
      "2019-06-18 16:00:46,420 epoch 14 - iter 261/294 - loss 0.83772966\n",
      "2019-06-18 16:01:06,818 epoch 14 - iter 290/294 - loss 0.82962598\n",
      "2019-06-18 16:01:09,467 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 16:01:09,469 EPOCH 14 done: loss 0.8270 - lr 0.1000 - bad epochs 0\n",
      "2019-06-18 16:01:23,969 DEV : loss 0.5880681276321411 - score 0.6518\n",
      "2019-06-18 16:02:08,595 TEST : loss 0.7544304728507996 - score 0.6229\n",
      "2019-06-18 16:02:08,603 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-18 16:02:09,942 epoch 15 - iter 0/294 - loss 0.26331484\n",
      "2019-06-18 16:02:33,490 epoch 15 - iter 29/294 - loss 0.73139401\n",
      "2019-06-18 16:02:54,322 epoch 15 - iter 58/294 - loss 0.78165639\n",
      "2019-06-18 16:03:16,931 epoch 15 - iter 87/294 - loss 0.76196905\n",
      "2019-06-18 16:03:35,608 epoch 15 - iter 116/294 - loss 0.76312824\n"
     ]
    }
   ],
   "source": [
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "## give your model a name and folder of your choice. Your model will be saved there for loading later \n",
    "## you can run this notebook many times with different embeddings/params and save the models with different names\n",
    "model_name = 'resources/taggers/resume-WEglove-CE'\n",
    "\n",
    "# 7. start training - you can experiment with batch size if you get memory errors\n",
    "# how many epochs does it take before the model stops showing improvement? Start with a big number like 150, and stop the code cell\n",
    "# from running at any time - the framework will persist the best model even if you interrupt training. \n",
    "trainer.train(model_name,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              #anneal_with_restarts=True,\n",
    "              max_epochs=20)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "flair_nlp_colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
